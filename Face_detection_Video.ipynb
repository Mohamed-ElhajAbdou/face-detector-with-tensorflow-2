{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Mohamed\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Mohamed\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "C:\\Users\\Mohamed\\Anaconda_3_v_1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Mohamed\\Anaconda_3_v_1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Mohamed\\Anaconda_3_v_1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Mohamed\\Anaconda_3_v_1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Mohamed\\Anaconda_3_v_1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Mohamed\\Anaconda_3_v_1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1025 17:20:25.758392 12372 deprecation.py:506] From C:\\Users\\Mohamed\\Anaconda_3_v_1\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1025 17:20:25.773989 12372 deprecation_wrapper.py:119] From C:\\Users\\Mohamed\\tensorflow\\Facenet-Real-time-face-recognition-using-deep-learning-Tensorflow2\\detect_face.py:177: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1025 17:20:25.836492 12372 deprecation.py:506] From C:\\Users\\Mohamed\\tensorflow\\Facenet-Real-time-face-recognition-using-deep-learning-Tensorflow2\\detect_face.py:220: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W1025 17:20:25.836492 12372 deprecation.py:506] From C:\\Users\\Mohamed\\tensorflow\\Facenet-Real-time-face-recognition-using-deep-learning-Tensorflow2\\detect_face.py:222: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W1025 17:20:25.836492 12372 deprecation.py:323] From C:\\Users\\Mohamed\\tensorflow\\Facenet-Real-time-face-recognition-using-deep-learning-Tensorflow2\\detect_face.py:223: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8ed0e7702591>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_device_placement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mpnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_face\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_mtcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mminsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m  \u001b[1;31m# minimum size of face\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tensorflow\\Facenet-Real-time-face-recognition-using-deep-learning-Tensorflow2\\detect_face.py\u001b[0m in \u001b[0;36mcreate_mtcnn\u001b[1;34m(sess, model_path)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[0mpnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[0mpnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'det1.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rnet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tensorflow\\Facenet-Real-time-face-recognition-using-deep-learning-Tensorflow2\\detect_face.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, data_path, session, ignore_missing)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mignore_missing\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mtrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserialized\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0mare\u001b[0m \u001b[0mignored\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         '''\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mdata_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pylint: disable=no-member\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mop_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[1;32m--> 453\u001b[1;33m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[0;32m    454\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# Try a pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m         \u001b[1;31m# The array contained Python objects. We need to unpickle the data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             raise ValueError(\"Object arrays cannot be loaded when \"\n\u001b[0m\u001b[0;32m    723\u001b[0m                              \"allow_pickle=False\")\n\u001b[0;32m    724\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpickle_kwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import facenet\n",
    "import detect_face\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "input_video=\"akshay_mov.mp4\"\n",
    "modeldir = './model/20170511-185253.pb'\n",
    "classifier_filename = './class/classifier.pkl'\n",
    "npy='./npy'\n",
    "train_img=\"./train_img\"\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.6)\n",
    "    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "    with sess.as_default():\n",
    "        pnet, rnet, onet = detect_face.create_mtcnn(sess, npy)\n",
    "\n",
    "        minsize = 20  # minimum size of face\n",
    "        threshold = [0.6, 0.7, 0.7]  # three steps's threshold\n",
    "        factor = 0.709  # scale factor\n",
    "        margin = 44\n",
    "        frame_interval = 3\n",
    "        batch_size = 1000\n",
    "        image_size = 182\n",
    "        input_image_size = 160\n",
    "        \n",
    "        HumanNames = os.listdir(train_img)\n",
    "        HumanNames.sort()\n",
    "\n",
    "        print('Loading Modal')\n",
    "        facenet.load_model(modeldir)\n",
    "        images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "        embedding_size = embeddings.get_shape()[1]\n",
    "\n",
    "\n",
    "        classifier_filename_exp = os.path.expanduser(classifier_filename)\n",
    "        with open(classifier_filename_exp, 'rb') as infile:\n",
    "            (model, class_names) = pickle.load(infile)\n",
    "\n",
    "        video_capture = cv2.VideoCapture(input_video)\n",
    "        c = 0\n",
    "\n",
    "\n",
    "        print('Start Recognition')\n",
    "        prevTime = 0\n",
    "        while True:\n",
    "            ret, frame = video_capture.read()\n",
    "\n",
    "            frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)    #resize frame (optional)\n",
    "\n",
    "            curTime = time.time()+1    # calc fps\n",
    "            timeF = frame_interval\n",
    "\n",
    "            if (c % timeF == 0):\n",
    "                find_results = []\n",
    "\n",
    "                if frame.ndim == 2:\n",
    "                    frame = facenet.to_rgb(frame)\n",
    "                frame = frame[:, :, 0:3]\n",
    "                bounding_boxes, _ = detect_face.detect_face(frame, minsize, pnet, rnet, onet, threshold, factor)\n",
    "                nrof_faces = bounding_boxes.shape[0]\n",
    "                print('Detected_FaceNum: %d' % nrof_faces)\n",
    "\n",
    "                if nrof_faces > 0:\n",
    "                    det = bounding_boxes[:, 0:4]\n",
    "                    img_size = np.asarray(frame.shape)[0:2]\n",
    "\n",
    "                    cropped = []\n",
    "                    scaled = []\n",
    "                    scaled_reshape = []\n",
    "                    bb = np.zeros((nrof_faces,4), dtype=np.int32)\n",
    "\n",
    "                    for i in range(nrof_faces):\n",
    "                        emb_array = np.zeros((1, embedding_size))\n",
    "\n",
    "                        bb[i][0] = det[i][0]\n",
    "                        bb[i][1] = det[i][1]\n",
    "                        bb[i][2] = det[i][2]\n",
    "                        bb[i][3] = det[i][3]\n",
    "\n",
    "                        # inner exception\n",
    "                        if bb[i][0] <= 0 or bb[i][1] <= 0 or bb[i][2] >= len(frame[0]) or bb[i][3] >= len(frame):\n",
    "                            print('Face is very close!')\n",
    "                            continue\n",
    "\n",
    "                        cropped.append(frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :])\n",
    "                        cropped[i] = facenet.flip(cropped[i], False)\n",
    "                        scaled.append(misc.imresize(cropped[i], (image_size, image_size), interp='bilinear'))\n",
    "                        scaled[i] = cv2.resize(scaled[i], (input_image_size,input_image_size),\n",
    "                                               interpolation=cv2.INTER_CUBIC)\n",
    "                        scaled[i] = facenet.prewhiten(scaled[i])\n",
    "                        scaled_reshape.append(scaled[i].reshape(-1,input_image_size,input_image_size,3))\n",
    "                        feed_dict = {images_placeholder: scaled_reshape[i], phase_train_placeholder: False}\n",
    "                        emb_array[0, :] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "                        predictions = model.predict_proba(emb_array)\n",
    "                        print(predictions)\n",
    "                        best_class_indices = np.argmax(predictions, axis=1)\n",
    "                        best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n",
    "                        # print(\"predictions\")\n",
    "                        print(best_class_indices,' with accuracy ',best_class_probabilities)\n",
    "\n",
    "                        # print(best_class_probabilities)\n",
    "                        if best_class_probabilities>0.53:\n",
    "                            cv2.rectangle(frame, (bb[i][0], bb[i][1]), (bb[i][2], bb[i][3]), (0, 255, 0), 2)    #boxing face\n",
    "\n",
    "                            #plot result idx under box\n",
    "                            text_x = bb[i][0]\n",
    "                            text_y = bb[i][3] + 20\n",
    "                            print('Result Indices: ', best_class_indices[0])\n",
    "                            print(HumanNames)\n",
    "                            for H_i in HumanNames:\n",
    "                                if HumanNames[best_class_indices[0]] == H_i:\n",
    "                                    result_names = HumanNames[best_class_indices[0]]\n",
    "                                    cv2.putText(frame, result_names, (text_x, text_y), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                                                1, (0, 0, 255), thickness=1, lineType=2)\n",
    "                else:\n",
    "                    print('Alignment Failure')\n",
    "            # c+=1\n",
    "            cv2.imshow('Video', frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.16.2\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/29/d97b6252591da5f8add0d25eecda296ea72729a0aad7998edba1981b47c8/numpy-1.16.2-cp36-cp36m-win_amd64.whl (11.9MB)\n",
      "Installing collected packages: numpy\n",
      "  Found existing installation: numpy 1.16.1\n",
      "    Uninstalling numpy-1.16.1:\n",
      "      Successfully uninstalled numpy-1.16.1\n",
      "Successfully installed numpy-1.16.2\n",
      "1.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.16.2\n",
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c8ec22b3e787>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-639e5d4f81da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "print(sys.path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
